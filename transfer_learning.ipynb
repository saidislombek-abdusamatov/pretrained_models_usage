{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_gbMdbC5Enj"
   },
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2T7vh6E54819"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gEGZRyzL5IBL"
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Data preprocessing\n",
    "x_train = tf.keras.applications.resnet50.preprocess_input(x_train.astype('float32'))\n",
    "x_test = tf.keras.applications.resnet50.preprocess_input(x_test.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Koz_TWtL5JJv"
   },
   "outputs": [],
   "source": [
    "# Initialize the model, excluding the last fully connected layer\n",
    "resnet50 = tf.keras.applications.ResNet50(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "# Freeze all the layers\n",
    "for layer in resnet50.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build model\n",
    "inputs = tf.keras.layers.Input(shape=(32,32,3))\n",
    "x = tf.keras.layers.UpSampling2D(size=(7,7))(inputs)\n",
    "x = resnet50(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "output = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Compile the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eg6ftjlg5U7j",
    "outputId": "8c58579a-30f2-4e92-b39a-254774aae793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2  (None, 224, 224, 3)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26215818 (100.01 MB)\n",
      "Trainable params: 2628106 (10.03 MB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZA7NeH75XDz",
    "outputId": "b683100c-451d-41d2-ec4f-bc44854c308e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 152s 183ms/step - loss: 0.8371 - accuracy: 0.7096\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 142s 182ms/step - loss: 0.5959 - accuracy: 0.7915\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 142s 182ms/step - loss: 0.5284 - accuracy: 0.8168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x79db904646d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgSr-3eoDF3J",
    "outputId": "c9bc3861-46d6-4587-9572-53e00e21d09f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 32s 95ms/step - loss: 0.7467 - accuracy: 0.7520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7466651201248169, 0.7519999742507935]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xq0RokLR7qV2"
   },
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VDXnx2Hm5Yrz"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3IaZS7AV80wa"
   },
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUFVV3nh83r7",
    "outputId": "53e8f2cf-6a1d-45c3-f558-d0fa2a0a3990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                             train=True,\n",
    "                                             download=True,\n",
    "                                             transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                             train=False,\n",
    "                                             transform=transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1RubE3iP8_WU"
   },
   "outputs": [],
   "source": [
    "# Load pretrained ResNet50 model\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT).to(device)\n",
    "\n",
    "# Freeze all layers in ResNet50\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Fully connected layer\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 10)\n",
    ").to(device)\n",
    "\n",
    "# Optimizer and loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIdFvszq-oBU",
    "outputId": "eaeef47d-51b1-4956-fbf3-cd014791c046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Training Loss: 0.0270  |  Training Accuracy: 0.3990\n",
      "Epoch 2/3\n",
      "Training Loss: 0.0245  |  Training Accuracy: 0.4559\n",
      "Epoch 3/3\n",
      "Training Loss: 0.0235  |  Training Accuracy: 0.4769\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "train_loss = 0.0\n",
    "train_acc = 0.0\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    # Print metrics\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc /= len(train_loader.dataset)\n",
    "\n",
    "    print(f'Training Loss: {train_loss:.4f}  |  Training Accuracy: {train_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJ1miI7eBAhx",
    "outputId": "1452d537-3962-470e-af4f-ad8e09109be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Validation Loss: 0.0246  |  Validation Accuracy: 0.4560\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "val_loss = 0.0\n",
    "val_acc = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Forward pass\n",
    "        val_loss += criterion(outputs, labels)\n",
    "        val_acc += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(test_loader.dataset)\n",
    "    val_acc /= len(test_loader.dataset)\n",
    "\n",
    "    print(f' Validation Loss: {val_loss:.4f}  |  Validation Accuracy: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "O-7-yiRaDTHk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
